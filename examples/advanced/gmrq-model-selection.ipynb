{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates the use of the cross-validation and the generalized matrix Rayleigh quotient (GMRQ) for selecting\n",
    "MSM hyperparameters. The GMRQ is a criterion which \"scores\" how well the MSM eigenvectors generated on the training dataset\n",
    "serve as slow coordinates for the test dataset [1].\n",
    "\n",
    "[1] McGibbon, R. T. and V. S. Pande, [Variational cross-validation of slow dynamical modes in molecular kinetics](http://arxiv.org/abs/1407.8083) (2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from msmbuilder.example_datasets import load_doublewell\n",
    "from msmbuilder.cluster import NDGrid\n",
    "from msmbuilder.msm import MarkovStateModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses the doublewell dataset, which consists of ten trajectories in 1D with $x \\in [-\\pi, \\pi]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trajectories = load_doublewell(random_state=0).trajectories\n",
    "# sub-sample a little bit, by taking only every 100th data point in each trajectory.\n",
    "trajectories = [t[::100] for t in trajectories]\n",
    "print([t.shape for t in trajectories])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `pipeline` is a way of connecting together multiple estimators, so that we can create a custom model that\n",
    "performs a sequence of steps. This model is relatively simple. It will first discretize the trajectory data\n",
    "onto an evenly spaced grid between $-\\pi$ and $\\pi$, and then build an MSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('grid', NDGrid(min=-np.pi, max=np.pi)),\n",
    "    ('msm', MarkovStateModel(n_timescales=1, lag_time=1, reversible_type='transpose', verbose=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation \n",
    "\n",
    "To get an accurate indication of how well our MSMs are doing at finding the dominant eigenfunctions\n",
    "of our stochastic process, we need to consider the tendenancy of statistical models to overfit their\n",
    "training data. Our MSMs might build transition matrices which fit the noise in training data as opposed\n",
    "to the underlying signal.\n",
    "\n",
    "One way to combat overfitting in a data-efficient way is with cross validation. This example uses 5-fold\n",
    "cross valiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_score(trajectories, model, n_states):\n",
    "    cv = KFold(len(trajectories), n_folds=5)\n",
    "    results = []\n",
    "\n",
    "    for n in n_states:\n",
    "        model.set_params(grid__n_bins_per_feature=n)\n",
    "        for fold, (train_index, test_index) in enumerate(cv):\n",
    "            train_data = [trajectories[i] for i in train_index]\n",
    "            test_data = [trajectories[i] for i in test_index]\n",
    "\n",
    "            # fit model with a subset of the data (training data).\n",
    "            # then we'll score it on both this training data (which\n",
    "            # will give an overly-rosy picture of its performance)\n",
    "            # and on the test data.\n",
    "            model.fit(train_data)\n",
    "            train_score = model.score(train_data)\n",
    "            test_score = model.score(test_data)\n",
    "\n",
    "            results.append({\n",
    "                'train_score': train_score,\n",
    "                'test_score': test_score,\n",
    "                'n_states': n,\n",
    "                'fold': fold})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = fit_and_score(trajectories, model, [5, 10, 25, 50, 100, 200, 500, 750])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame(results)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(results['n_states'], results['train_score'], c='b', marker='.', ls='')\n",
    "plt.plot(results['n_states'], results['test_score'], c='r', marker='.', ls='')\n",
    "\n",
    "mean_over_folds = results.groupby('n_states').aggregate(np.mean)\n",
    "plt.plot(mean_over_folds.index, mean_over_folds['test_score'], c='r', marker='.', ls='-', label='Mean test')\n",
    "plt.plot(mean_over_folds.index, mean_over_folds['train_score'], c='b', marker='.', ls='-', label='Mean train')\n",
    "plt.semilogx()\n",
    "plt.ylabel('Generalized Matrix Rayleigh Quotient (Score)')\n",
    "plt.xlabel('Number of states')\n",
    "\n",
    "best_n_states = np.argmax(mean_over_folds['test_score'])\n",
    "best_test_score = mean_over_folds.ix[best_n_states]['test_score']\n",
    "plt.plot(best_n_states, best_test_score, marker='*', ms=20, c='w', label='n_states=%d' % best_n_states)\n",
    "\n",
    "plt.legend(loc='best', numpoints=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is very similar to figure 1 from [McGibbon and Pande](http://arxiv.org/abs/1407.8083). It shows\n",
    "that the performance on the training set keeps going up as we increase the number of states (with the\n",
    "amount of data fixed), whereas the test performance peaks and then starts going down.\n",
    "\n",
    "We should pick the model with the highest average test set performance. In this example, we're only choosing over\n",
    "the number of MSMs states, but this method can also be used to evaluate the clustering method and any pre-processing\n",
    "like tICA.\n",
    "\n",
    "However, you do need to fix the number of dynamical processes to \"score\" (this is the `n_timescales` attribute for `MarkovStateModel`), as well as the lag time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
